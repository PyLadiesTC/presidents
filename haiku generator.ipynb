{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_by_participant(debate):\n",
    "    participant = {}\n",
    "    current_speaker = ''\n",
    "    for line in debate:\n",
    "        line = line.strip()\n",
    "        speaker = re.match(\"[A-Z]'?[A-Z]+:\",line)\n",
    "        if speaker:\n",
    "            speaker = speaker.group(0).strip(':').strip()\n",
    "            if 'MALLEY' in speaker:\n",
    "                speaker = \"O'MALLEY\"\n",
    "            if speaker not in participant.keys():\n",
    "                participant[speaker] = []\n",
    "            current_speaker = speaker\n",
    "        else:\n",
    "            if len(line) > 0:\n",
    "                try:\n",
    "                    participant[current_speaker].append(line)\n",
    "                except:\n",
    "                    print current_speaker\n",
    "    return participant\n",
    "\n",
    "def make_corpus(speech):\n",
    "    joined_speech = []\n",
    "    for turn in speech:\n",
    "        line = turn\n",
    "        line = re.sub('([a-zA-Z])[\\./]([a-zA-Z])',r'\\1 \\2',line)\n",
    "        line = re.sub('\\[.*?\\]','',line)\n",
    "        # words = nltk.word_tokenize(line.strip())\n",
    "        sent_tokenize_list = sent_tokenize(line)\n",
    "        for sentence in sent_tokenize_list:\n",
    "            sentence_words = []\n",
    "            words = word_tokenize(sentence.strip())\n",
    "            for word in words:\n",
    "                word = word.lower().strip().strip('.').strip(':')\n",
    "                if len(word) != 0:\n",
    "                    if (word != \"``\") and (word != \"--\") and (word != \"'\"):\n",
    "                        if re.search('.*[^a-zA-Z0-9\\'\\-]',word):\n",
    "                            if (len(word) >= 2):\n",
    "                                sentence_words.append(word)\n",
    "                                # joined_speech.append(word)\n",
    "                        else:\n",
    "                            sentence_words.append(word)\n",
    "                            # joined_speech.append(word)\n",
    "            joined_speech.append(sentence_words)\n",
    "    return joined_speech\n",
    "\n",
    "def get_corpus(participant):\n",
    "    corpus = {}\n",
    "    for person in participant.keys():\n",
    "        corpus[person] = make_corpus(participant[person])\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in os.listdir('debates'):\n",
    "    if re.search('[RD].*201[56]',f):\n",
    "    #if re.search('[RD].*200[78]',f):\n",
    "        raw = []\n",
    "        ifile = open('debates/'+f,'r')\n",
    "        raw = ifile.readlines()\n",
    "        ifile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "debate = []\n",
    "for line in raw:\n",
    "    line = line.decode('utf8', 'ignore')\n",
    "    line = line.encode('ascii', 'ignore')\n",
    "    debate.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "participant = sort_by_participant(debate)\n",
    "corpus = get_corpus(participant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = corpus['TRUMP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('dearsister_cut.txt')\n",
    "raw = f.read()\n",
    "raw = raw.decode('utf8', 'ignore')\n",
    "raw = raw.encode('ascii', 'ignore')\n",
    "sent_tokenize_list = sent_tokenize(raw)\n",
    "text = []\n",
    "for sentence in sent_tokenize_list:\n",
    "    words = word_tokenize(sentence)\n",
    "    text.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# Functions to generate LMs:\n",
    "def get_unigram(sents):\n",
    "    fd = nltk.FreqDist()\n",
    "    for sent in sents:\n",
    "        for word in sent:\n",
    "            fd[word] += 1    \n",
    "\n",
    "    return nltk.MLEProbDist(fd)\n",
    "\n",
    "def get_bigram(sents):\n",
    "    cfd = nltk.ConditionalFreqDist()\n",
    "    for sent in sents:\n",
    "        prev = '<s>'\n",
    "        for word in sent:\n",
    "            cfd[prev][word] += 1\n",
    "            prev = word\n",
    "        cfd[word]['</s>'] += 1\n",
    "    return nltk.ConditionalProbDist(cfd, nltk.MLEProbDist)\n",
    "\n",
    "def get_trigram(sents):\n",
    "    cfd = nltk.ConditionalFreqDist()\n",
    "    for sent in sents:\n",
    "        cond1 = '<s>'\n",
    "        cond2 = '<s>'\n",
    "        for word in sent:\n",
    "            context = \" \".join([cond1, cond2])\n",
    "            cfd[context][word] += 1\n",
    "            cond1 = cond2\n",
    "            cond2 = word\n",
    "    return nltk.ConditionalProbDist(cfd, nltk.MLEProbDist)\n",
    "\n",
    "\n",
    "# Functions to generate random sentences based on LM:\n",
    "def generate_random_unigram(n, model):\n",
    "    words = []\n",
    "    for i in range(n):\n",
    "        word = model.generate()\n",
    "        words.append(word)\n",
    "    return \" \".join(words)\n",
    "    \n",
    "def generate_random_bigram(n, model):\n",
    "    words = []\n",
    "    condition = '<s>'\n",
    "    for i in range(n):\n",
    "        word = model[condition].generate()\n",
    "        if word == '</s>':\n",
    "            condition = '<s>'\n",
    "        else:\n",
    "            words.append(word)\n",
    "            condition = word\n",
    "    return \" \".join(words)\n",
    "\n",
    "def generate_random_trigram(n, model):\n",
    "    words = []\n",
    "    condition = '<s> <s>'\n",
    "    for i in range(n):\n",
    "        try:\n",
    "            word = model[condition].generate()\n",
    "            if word in ['.', '?', '!']:\n",
    "                words.append(word)\n",
    "                condition = '<s> <s>'\n",
    "            else:\n",
    "                words.append(word)\n",
    "                condition = \" \".join([condition.split()[-1], word])\n",
    "        except:\n",
    "            pass\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "\n",
    "def text_loop(text_dict):\n",
    "    \n",
    "    text_no = len(text_dict.keys()) - 1\n",
    "    text_key = None\n",
    "    print \"Choose a text from the following list: \"\n",
    "    for key, value in text_dict.items():\n",
    "        print \"   %s: %s\" % (key, value)\n",
    "\n",
    "    print \"\"\n",
    "    while text_key == None:\n",
    "\n",
    "        text_key = int(raw_input(\"Please enter a number between 0-%s: \" % text_no))\n",
    "\n",
    "        if text_key > max(text_dict.keys()):\n",
    "            text_key = None\n",
    "            print \"Not a valid option.\",\n",
    "\n",
    "    return text_key\n",
    "\n",
    "def prompt_lm(text):\n",
    "    lm = raw_input(\"Choose a LM. Enter 'unigram', 'bigram' or 'trigram': \")\n",
    "    if lm == 'unigram':\n",
    "        model = get_unigram(text)\n",
    "        generator = generate_random_unigram\n",
    "        return model, generator\n",
    "    elif lm == 'bigram':\n",
    "        model = get_bigram(text)\n",
    "        generator = generate_random_bigram\n",
    "        return model, generator\n",
    "    elif lm == 'trigram':\n",
    "        model = get_trigram(text)\n",
    "        generator = generate_random_trigram\n",
    "        return model, generator\n",
    "    else:\n",
    "        sys.exit(\"Something is wrong. Try again.\")\n",
    "\n",
    "def sentence_generation(model, generator):\n",
    "    length = None\n",
    "    while not length == 0:\n",
    "        length = int(raw_input(\n",
    "            \"Enter the length of sentence you'd like to generate (or 0 to exit): \"))\n",
    "        print '\\n' + generator(length, model) + '\\n'\n",
    "        \n",
    "def make_haiku(model, generator):\n",
    "    \n",
    "    nsyls = 0\n",
    "    \n",
    "    while nsyls != 5:\n",
    "        length = random.randint(1,5)\n",
    "        line1 = generator(length, model)\n",
    "        nsyls = nsyl(line1)\n",
    "    \n",
    "    nsyls = 0\n",
    "    while nsyls != 7:\n",
    "        nsyls = 0\n",
    "        length = random.randint(1,7)\n",
    "        line2 = generator(length, model)\n",
    "        nsyls = nsyl(line2)\n",
    "    \n",
    "    nsyls = 0\n",
    "    while nsyls != 5:\n",
    "        length = random.randint(1,5)\n",
    "        line3 = generator(length, model)\n",
    "        nsyls = nsyl(line3)\n",
    "        \n",
    "    print \"\\n{0}\\n{1}\\n{2}\".format(line1, line2, line3)\n",
    "\n",
    "def nsyl(sentence):\n",
    "    d = cmudict.dict()\n",
    "    words = sentence.split(' ')\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        try:\n",
    "            count += [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]][0]\n",
    "        except:\n",
    "            count = 0\n",
    "    return count\n",
    "\n",
    "def main(text):\n",
    "    model, generator = prompt_lm(text)\n",
    "    #sentence_generation(model, generator)\n",
    "    make_haiku(model, generator)\n",
    "\n",
    "    prompt = raw_input(\"Do you want to try again (type 'yes' or 'no'): \")\n",
    "    if prompt == 'yes':\n",
    "        main(text)\n",
    "    else:\n",
    "        print \"Goodbye!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose a LM. Enter 'unigram', 'bigram' or 'trigram': trigram\n",
      "(5, 0)\n",
      "(5, 1)\n",
      "(5, 2)\n",
      "(5, 3)\n",
      "(5, 4)\n",
      "(4, 0)\n",
      "(4, 1)\n",
      "(4, 2)\n",
      "(4, 3)\n",
      "(2, 0)\n",
      "(2, 1)\n",
      "(4, 0)\n",
      "(4, 1)\n",
      "(4, 2)\n",
      "(4, 3)\n",
      "(3, 0)\n",
      "(3, 1)\n",
      "(3, 2)\n",
      "(1, 0)\n",
      "(5, 0)\n",
      "(5, 1)\n",
      "(5, 2)\n",
      "(5, 3)\n",
      "(5, 4)\n",
      "(2, 0)\n",
      "(2, 1)\n",
      "(5, 0)\n",
      "(5, 1)\n",
      "(5, 2)\n",
      "(5, 3)\n",
      "(5, 4)\n",
      "(3, 0)\n",
      "(3, 1)\n",
      "(3, 2)\n",
      "(2, 0)\n",
      "(2, 1)\n",
      "(3, 0)\n",
      "(3, 1)\n",
      "(3, 2)\n",
      "(5, 0)\n",
      "(5, 1)\n",
      "(5, 2)\n",
      "(5, 3)\n",
      "(5, 4)\n",
      "(5, 0)\n",
      "(5, 1)\n",
      "(5, 2)\n",
      "(5, 3)\n",
      "(5, 4)\n",
      "(5, 0)\n",
      "(5, 1)\n",
      "(5, 2)\n",
      "(5, 3)\n",
      "(5, 4)\n",
      "(4, 0)\n",
      "(4, 1)\n",
      "(4, 2)\n",
      "(4, 3)\n",
      "\n",
      "i say not in a\n",
      "i 'm a businessman did\n",
      "got along with all\n",
      "Do you want to try again (type 'yes' or 'no'): yes\n"
     ]
    }
   ],
   "source": [
    "main(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
